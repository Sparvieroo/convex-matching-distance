{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chaotic Attractors — Pairwise Distance Quality\n",
    "\n",
    "Bifiltration: $\\sqrt{\\alpha}$ + eccentricity (Alpha complex).\n",
    "$n = 1000$, noise $= 0$, 200 samples per class (1000 total).\n",
    "CMD, MD 121, MD 10 for all pairs, separately for $H_0$ and $H_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd\n",
    "from scipy.integrate import solve_ivp\n",
    "from sklearn.metrics import pairwise_distances as pdist_sklearn\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD: 11 | MD fine: 121 | MD coarse: 10\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "n_ex = 200\n",
    "ALPHA_CLIP = 0.15\n",
    "\n",
    "t_values = np.linspace(0, 1, 11)\n",
    "a_fine = np.linspace(0.05, 0.95, 11)\n",
    "b_fine = np.linspace(0, 1, 11)\n",
    "a_coarse = np.array([0.25, 0.75])\n",
    "b_coarse = np.linspace(0, 1, 5)\n",
    "BOTTLENECK_E = 0.01\n",
    "\n",
    "n_cmd = len(t_values)\n",
    "n_md_fine = len(a_fine) * len(b_fine)\n",
    "n_md_coarse = len(a_coarse) * len(b_coarse)\n",
    "print(f'CMD: {n_cmd} | MD fine: {n_md_fine} | MD coarse: {n_md_coarse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorenz_rhs(t, s):\n",
    "    x, y, z = s\n",
    "    return [10.0*(y-x), x*(28.0-z)-y, x*y-8.0/3.0*z]\n",
    "def rossler_rhs(t, s):\n",
    "    x, y, z = s\n",
    "    return [-(y+z), x+0.2*y, 0.2+z*(x-5.7)]\n",
    "def thomas_rhs(t, s):\n",
    "    x, y, z = s\n",
    "    b = 0.208186\n",
    "    return [np.sin(y)-b*x, np.sin(z)-b*y, np.sin(x)-b*z]\n",
    "def sprott_rhs(t, s):\n",
    "    x, y, z = s\n",
    "    return [y+2.07*x*y+x*z, 1.0-1.79*x**2+y*z, x-x**2-y**2]\n",
    "def fourwing_rhs(t, s):\n",
    "    x, y, z = s\n",
    "    return [0.2*x+y*z, 0.01*x-0.4*y-x*z, -z-x*y]\n",
    "\n",
    "attractor_configs = [\n",
    "    (lorenz_rhs,   20, 100, 5.0),\n",
    "    (rossler_rhs,  50, 200, 1.0),\n",
    "    (thomas_rhs,  100, 500, 1.0),\n",
    "    (sprott_rhs,   50, 200, 0.5),\n",
    "    (fourwing_rhs, 50, 300, 0.1),\n",
    "]\n",
    "attractor_names = ['Lorenz', 'Rössler', 'Thomas', 'Sprott', 'Four-Wing']\n",
    "n_classes = len(attractor_configs)\n",
    "\n",
    "def generate_attractor(cls_idx, n_pts=1000, seed=None):\n",
    "    rhs, t_burn, t_run, x0_scale = attractor_configs[cls_idx]\n",
    "    rng = np.random.RandomState(seed)\n",
    "    x0 = rng.uniform(-x0_scale, x0_scale, 3)\n",
    "    sol0 = solve_ivp(rhs, [0, t_burn], x0, rtol=1e-8, atol=1e-8, dense_output=True)\n",
    "    y0 = sol0.y[:, -1]\n",
    "    n_dense = max(10000, 20*n_pts)\n",
    "    t_eval = np.linspace(0, t_run, n_dense)\n",
    "    sol = solve_ivp(rhs, [0, t_run], y0, t_eval=t_eval, rtol=1e-8, atol=1e-8)\n",
    "    traj = sol.y.T\n",
    "    idx = np.linspace(0, len(traj)-1, n_pts, dtype=int)\n",
    "    pts = traj[idx].copy()\n",
    "    pmin, pmax = pts.min(axis=0), pts.max(axis=0)\n",
    "    rng_vals = pmax - pmin\n",
    "    rng_vals[rng_vals < 1e-12] = 1.0\n",
    "    pts = (pts - pmin) / rng_vals\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1000 (5 classes x 200 samples)\n"
     ]
    }
   ],
   "source": [
    "Data, Labels = [], []\n",
    "for cls_idx in range(n_classes):\n",
    "    for s in range(n_ex):\n",
    "        Labels.append(cls_idx)\n",
    "        Data.append(generate_attractor(cls_idx, n_pts=n, seed=s*1000+cls_idx))\n",
    "Labels = np.array(Labels)\n",
    "N = len(Data)\n",
    "print(f'N = {N} ({n_classes} classes x {n_ex} samples)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedAlpha:\n",
    "    def __init__(self, points):\n",
    "        ac = gd.AlphaComplex(points=points)\n",
    "        self.st = ac.create_simplex_tree()\n",
    "        self._simplices = []\n",
    "        self._alpha_vals = []\n",
    "        for s, fv in self.st.get_simplices():\n",
    "            self._simplices.append(tuple(s))\n",
    "            self._alpha_vals.append(self.st.filtration(s))\n",
    "        self._alpha_vals = np.array(self._alpha_vals)\n",
    "        max_dim = max(len(s) for s in self._simplices)\n",
    "        self._vert_idx = np.full((len(self._simplices), max_dim), -1, dtype=np.int32)\n",
    "        for i, s in enumerate(self._simplices):\n",
    "            self._vert_idx[i, :len(s)] = s\n",
    "    def compute_pd(self, func_values):\n",
    "        f_ext = np.append(func_values, -np.inf)\n",
    "        filt_vals = np.max(f_ext[self._vert_idx], axis=1)\n",
    "        for i, s in enumerate(self._simplices):\n",
    "            self.st.assign_filtration(s, float(filt_vals[i]))\n",
    "        self.st.make_filtration_non_decreasing()\n",
    "        self.st.persistence()\n",
    "        pds = []\n",
    "        for dim in range(2):\n",
    "            pd = self.st.persistence_intervals_in_dimension(dim)\n",
    "            if pd is not None and len(pd) > 0:\n",
    "                pd = pd[np.isfinite(pd[:, 1])]\n",
    "            if pd is None or len(pd) == 0:\n",
    "                pd = np.empty((0, 2))\n",
    "            pds.append(pd)\n",
    "        return tuple(pds)\n",
    "\n",
    "def phi_star_ab(phi1, phi2, a, b):\n",
    "    return np.minimum(a, 1-a) * np.maximum((phi1-b)/a, (phi2+b)/(1-a))\n",
    "\n",
    "def safe_bottleneck(pd1, pd2, e=0.01):\n",
    "    if len(pd1) == 0 and len(pd2) == 0: return 0.0\n",
    "    if len(pd1) == 0: return float(np.max((pd2[:,1]-pd2[:,0])/2))\n",
    "    if len(pd2) == 0: return float(np.max((pd1[:,1]-pd1[:,0])/2))\n",
    "    return gd.bottleneck_distance(pd1, pd2, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtrations: 100%|██████████| 1000/1000 [00:24<00:00, 41.39it/s]\n",
      "PDs: 100%|██████████| 1000/1000 [35:53<00:00,  2.15s/it] \n"
     ]
    }
   ],
   "source": [
    "# Filtrations: sqrt(alpha) clipped + eccentricity\n",
    "Phi1, Phi2 = [], []\n",
    "Alphas = []\n",
    "for data in tqdm(Data, desc='Filtrations'):\n",
    "    ac = gd.AlphaComplex(points=data)\n",
    "    st = ac.create_simplex_tree()\n",
    "    alpha_vals = np.array([st.filtration([v]) for v in range(len(data))])\n",
    "    alpha_sqrt = np.sqrt(np.clip(alpha_vals, 0, None))\n",
    "    alpha_sqrt = np.clip(alpha_sqrt, 0, ALPHA_CLIP)\n",
    "    alpha_sqrt = alpha_sqrt / ALPHA_CLIP  # normalize to [0,1]\n",
    "    Phi1.append(alpha_sqrt)\n",
    "    ecc = np.max(pdist_sklearn(data), axis=1)\n",
    "    ecc = (ecc - ecc.min()) / (ecc.max() - ecc.min()) if ecc.max() > ecc.min() else ecc\n",
    "    Phi2.append(ecc)\n",
    "\n",
    "def make_cmd_filts(p1, p2): return [(1-t)*p1 + t*p2 for t in t_values]\n",
    "def make_mdf_filts(p1, p2): return [phi_star_ab(p1, p2, a, b) for a in a_fine for b in b_fine]\n",
    "def make_mdc_filts(p1, p2): return [phi_star_ab(p1, p2, a, b) for a in a_coarse for b in b_coarse]\n",
    "\n",
    "params = [('cmd', make_cmd_filts, n_cmd),\n",
    "          ('mdf', make_mdf_filts, n_md_fine),\n",
    "          ('mdc', make_mdc_filts, n_md_coarse)]\n",
    "\n",
    "PDs = {name: [None]*N for name, _, _ in params}\n",
    "for i in tqdm(range(N), desc='PDs'):\n",
    "    cst = CachedAlpha(Data[i])\n",
    "    phi1, phi2 = Phi1[i], Phi2[i]\n",
    "    for name, make_filts, _ in params:\n",
    "        PDs[name][i] = [cst.compute_pd(f) for f in make_filts(phi1, phi2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: cmd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: mdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: mdc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "Ds = {}\n",
    "for name, _, nparam in params:\n",
    "    print(f'Distances: {name}')\n",
    "    D_H0 = np.zeros((N, N))\n",
    "    D_H1 = np.zeros((N, N))\n",
    "    for i in tqdm(range(N), leave=False):\n",
    "        for j in range(i+1, N):\n",
    "            max_d0 = max_d1 = 0.0\n",
    "            for p in range(nparam):\n",
    "                d0 = safe_bottleneck(PDs[name][i][p][0], PDs[name][j][p][0], BOTTLENECK_E)\n",
    "                d1 = safe_bottleneck(PDs[name][i][p][1], PDs[name][j][p][1], BOTTLENECK_E)\n",
    "                if d0 > max_d0: max_d0 = d0\n",
    "                if d1 > max_d1: max_d1 = d1\n",
    "            D_H0[i,j] = D_H0[j,i] = max_d0\n",
    "            D_H1[i,j] = D_H1[j,i] = max_d1\n",
    "    Ds[name] = {'H0': D_H0, 'H1': D_H1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Attractors_distances.npy', {\n",
    "    'd_cmd_H0': Ds['cmd']['H0'], 'd_cmd_H1': Ds['cmd']['H1'],\n",
    "    'd_mdf_H0': Ds['mdf']['H0'], 'd_mdf_H1': Ds['mdf']['H1'],\n",
    "    'd_mdc_H0': Ds['mdc']['H0'], 'd_mdc_H1': Ds['mdc']['H1'],\n",
    "    'labels': Labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H0:\n",
      "  Spearman CMD vs MD121: 0.9999\n",
      "  Spearman MD10 vs MD121: 0.9998\n",
      "  Spearman CMD vs MD10: 0.9997\n",
      "\n",
      "H1:\n",
      "  Spearman CMD vs MD121: 0.9958\n",
      "  Spearman MD10 vs MD121: 0.9915\n",
      "  Spearman CMD vs MD10: 0.9819\n"
     ]
    }
   ],
   "source": [
    "triu = np.triu_indices(N, k=1)\n",
    "for hdim in ['H0', 'H1']:\n",
    "    d_cmd = Ds['cmd'][hdim][triu]\n",
    "    d_mdf = Ds['mdf'][hdim][triu]\n",
    "    d_mdc = Ds['mdc'][hdim][triu]\n",
    "    sp_cmd_mdf, _ = spearmanr(d_mdf, d_cmd)\n",
    "    sp_mdc_mdf, _ = spearmanr(d_mdf, d_mdc)\n",
    "    sp_cmd_mdc, _ = spearmanr(d_cmd, d_mdc)\n",
    "    print(f'\\n{hdim}:')\n",
    "    print(f'  Spearman CMD vs MD121: {sp_cmd_mdf:.4f}')\n",
    "    print(f'  Spearman MD10 vs MD121: {sp_mdc_mdf:.4f}')\n",
    "    print(f'  Spearman CMD vs MD10: {sp_cmd_mdc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
