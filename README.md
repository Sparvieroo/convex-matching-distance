# Convex Matching Distance — Experimental Results

Comparison of three approximation strategies for the matching distance between multiparameter persistence modules.

## Methods

All methods start from a bifiltration $(\varphi_1, \varphi_2)$ and compute 1-parameter persistence diagrams along selected lines in parameter space. The distance between two objects is the supremum of the bottleneck distances across all chosen lines.

| Method | Parameters | Description |
|--------|-----------|-------------|
| **CMD** | 11 | Convex combinations $(1-t)\varphi_1 + t\varphi_2$, $t \in \{0, 0.1, \ldots, 1\}$ |
| **MD 121** | 121 | Folding lines $\varphi^*_{a,b}$, $(a,b)$ on an $11 \times 11$ grid |
| **MD 10** | 10 | Folding lines $\varphi^*_{a,b}$, $(a,b)$ on a $2 \times 5$ grid |

Classification: $k$-NN ($k=3$) with most-confident selection across $H_0$ and $H_1$, 10-fold cross-validation.

## Experiments

### 1. Synthetic shapes (classification)

Five classes of 3D point clouds in $[0,1]^3$: circle, sphere, torus, 3 clusters, 2 concentric circles. Bifiltration: $\varphi_1$ = codensity ($k=15$), $\varphi_2$ = eccentricity, both normalized to $[0,1]$. Persistent homology via Alpha complex with lower-star extension. 40 samples per class (200 total), noise levels $\sigma \in \{0.00, 0.03, 0.06, 0.09, 0.12\}$, sample sizes $n \in \{500, 1000, 5000\}$.

**1-PH baselines**: Alpha 1-PH, codensity lower-star, eccentricity lower-star.

### 2. Chaotic attractors (classification)

Five classes of 3D chaotic attractors: Lorenz, Rössler, Thomas, Sprott, Four-Wing. Bifiltration: $\varphi_1$ = $\sqrt{\alpha}$ (Alpha complex filtration values, clipped at 0.15 and normalized), $\varphi_2$ = eccentricity (lower-star extension), both in $[0,1]$. Points rescaled to the unit cube $[0,1]^3$. 40 samples per class (200 total), $n = 500$.

**1-PH baselines**: Alpha 1-PH, eccentricity lower-star.

### 3. MNIST digits (distance quality)

Three topologically distinct digit classes ($H_1 = 0, 1, 2$). Bifiltration on cubical complex: $\varphi_1$ = inverted pixel intensity ($1 - \text{img}/255$), $\varphi_2$ = radial distance from center (normalized, on active pixels; 1.0 on inactive pixels). 100 samples per class (300 total, 44850 pairs).

This experiment directly evaluates distance quality rather than classification accuracy:
- **Stability verification**: $d \leq \|f - g\|_\infty$ for all pairs (zero violations).
- **Correlation with MD 121**: Spearman correlation of CMD = 0.993 vs MD 10 = 0.951.
- **Mean absolute error from MD 121**: CMD = 0.006 vs MD 10 = 0.028 (CMD is 5× closer).

## Key Findings

**CMD approximates MD 121 faithfully.** On MNIST, CMD (11 parameters) achieves Spearman correlation 0.993 with MD 121 and MAE 5× smaller than MD 10. CMD is more discriminative than MD 121 in 50% of pairs.

**CMD matches MD 121 in classification.** On synthetic shapes, CMD and MD 121 achieve comparable accuracy across all noise levels and sample sizes, while MD 10 degrades significantly under stress. At $n=5000, \sigma=0.06$: CMD 97.5%, MD 121 94.2%, MD 10 80.8%. At $n=5000, \sigma=0.12$: CMD 78.2%, MD 121 81.0%, MD 10 58.0%.

**Bifiltration captures complementary information.** On chaotic attractors, the bifiltration (CMD 95.2%, MD 121 96.5%, MD 10 93.8%) dramatically outperforms single-parameter persistence (Alpha 1-PH 54.5%, eccentricity 1-PH 31.5%). On synthetic shapes at $n=5000, \sigma=0.06$, the best 1-PH baseline (codensity, 84.3%) is well below all bifiltration methods.

**CMD is ~11× faster than MD 121.** Computational cost scales linearly with the number of bottleneck distance computations per pair.

## Folder Structure

```
Convex_matching/
├── README.md
├── Synthetic_noise.ipynb         # Synthetic shapes: CMD vs MD
├── Synthetic_1ph.ipynb           # Synthetic shapes: 1-PH baselines
├── Attractors.ipynb              # Chaotic attractors: CMD vs MD
├── Attractors_1ph.ipynb          # Chaotic attractors: 1-PH baselines
├── MNIST_distance.ipynb          # MNIST: distance quality (stability)
├── Analyze_results.ipynb         # Figures, tables, LaTeX output
├── Results/
│   ├── Synthetic_500.npy
│   ├── Synthetic_1000.npy
│   ├── Synthetic_5000.npy
│   ├── Synthetic_1ph_500.npy
│   ├── Synthetic_1ph_1000.npy
│   ├── Synthetic_1ph_5000.npy
│   ├── Attractors_500.npy
│   ├── Attractors_1ph_500.npy
│   └── MNIST_stability.npy
└── Plots/                        # PDF figures (generated by Analyze_results)
```

## Reproducibility

Results are stored as `.npy` dictionaries. Load with `np.load(path, allow_pickle=True).item()`.

- **Synthetic/Attractors classification**: `{noise_level: {'cmd': [...], 'mdf': [...], 'mdc': [...]}}` — each value is a list of 10-fold accuracies.
- **1-PH baselines**: `{noise_level: {'Alpha 1-PH': [...], 'Codensity lower-star': [...], ...}}`.
- **MNIST stability**: `{'d_linf': NxN, 'd_cmd': NxN, 'd_mdf': NxN, 'd_mdc': NxN, 'labels': N}`.

All experiments use `random_state=42`. Bottleneck distance approximation: $\varepsilon = 0.01$.
