{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Shapes — Pairwise Distance Quality\n",
    "\n",
    "Bifiltration: codensity + eccentricity (Alpha complex, lower-star).\n",
    "$n = 1000$, noise $= 0$, 200 samples per class (1000 total).\n",
    "CMD, MD 121, MD 10 for all pairs, separately for $H_0$ and $H_1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances as pdist_sklearn\n",
    "from scipy.stats import spearmanr\n",
    "from tqdm import tqdm\n",
    "import time, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMD: 11 | MD fine: 121 | MD coarse: 10\n"
     ]
    }
   ],
   "source": [
    "n = 500\n",
    "n_ex = 100\n",
    "k_neighbors = 15\n",
    "\n",
    "t_values = np.linspace(0, 1, 11)\n",
    "a_fine = np.linspace(0.05, 0.95, 11)\n",
    "b_fine = np.linspace(0, 1, 11)\n",
    "a_coarse = np.array([0.25, 0.75])\n",
    "b_coarse = np.linspace(0, 1, 5)\n",
    "BOTTLENECK_E = 0.01\n",
    "\n",
    "n_cmd = len(t_values)\n",
    "n_md_fine = len(a_fine) * len(b_fine)\n",
    "n_md_coarse = len(a_coarse) * len(b_coarse)\n",
    "print(f'CMD: {n_cmd} | MD fine: {n_md_fine} | MD coarse: {n_md_coarse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_circle(n, noise=0.0):\n",
    "    theta = np.random.uniform(0, 2*np.pi, n)\n",
    "    pts = np.column_stack([0.5+0.4*np.cos(theta), 0.5*np.ones(n), 0.5+0.4*np.sin(theta)])\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "def generate_sphere(n, noise=0.0):\n",
    "    phi = np.random.uniform(0, 2*np.pi, n)\n",
    "    cos_theta = np.random.uniform(-1, 1, n)\n",
    "    sin_theta = np.sqrt(1 - cos_theta**2)\n",
    "    pts = np.column_stack([0.5+0.4*sin_theta*np.cos(phi), 0.5+0.4*sin_theta*np.sin(phi), 0.5+0.4*cos_theta])\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "def generate_torus(n, noise=0.0):\n",
    "    R, r = 0.3, 0.1\n",
    "    theta = np.random.uniform(0, 2*np.pi, n)\n",
    "    phi = np.random.uniform(0, 2*np.pi, n)\n",
    "    pts = np.column_stack([0.5+(R+r*np.cos(phi))*np.cos(theta), 0.5+(R+r*np.cos(phi))*np.sin(theta), 0.5+r*np.sin(phi)])\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "def generate_three_clusters(n, noise=0.0):\n",
    "    centers = np.array([[0.25,0.25,0.5],[0.75,0.25,0.5],[0.5,0.75,0.5]])\n",
    "    n_per = n // 3\n",
    "    parts = [c + np.random.normal(0, 0.06, (n_per if i < 2 else n-2*n_per, 3)) for i, c in enumerate(centers)]\n",
    "    pts = np.vstack(parts)\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "def generate_two_circles(n, noise=0.0):\n",
    "    n1 = n // 2; n2 = n - n1\n",
    "    t1 = np.random.uniform(0, 2*np.pi, n1)\n",
    "    t2 = np.random.uniform(0, 2*np.pi, n2)\n",
    "    pts = np.vstack([\n",
    "        np.column_stack([0.5+0.2*np.cos(t1), 0.5+0.2*np.sin(t1), 0.5*np.ones(n1)]),\n",
    "        np.column_stack([0.5+0.4*np.cos(t2), 0.5+0.4*np.sin(t2), 0.5*np.ones(n2)])])\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "\n",
    "generators = [generate_circle, generate_sphere, generate_torus, generate_three_clusters, generate_two_circles]\n",
    "shape_names = ['Circle', 'Sphere', 'Torus', '3 Clusters', '2 Circles']\n",
    "n_classes = len(generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 500 (5 classes x 100 samples)\n"
     ]
    }
   ],
   "source": [
    "Data, Labels = [], []\n",
    "for cls_idx, gen in enumerate(generators):\n",
    "    for _ in range(n_ex):\n",
    "        Labels.append(cls_idx)\n",
    "        Data.append(gen(n, noise=0.0))\n",
    "Labels = np.array(Labels)\n",
    "N = len(Data)\n",
    "print(f'N = {N} ({n_classes} classes x {n_ex} samples)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_codensity(points, k):\n",
    "    nn = NearestNeighbors(n_neighbors=k+1).fit(points)\n",
    "    return nn.kneighbors(points)[0][:, -1]\n",
    "def compute_eccentricity(points):\n",
    "    return np.max(pdist_sklearn(points), axis=1)\n",
    "\n",
    "class CachedSimplexTree:\n",
    "    def __init__(self, points):\n",
    "        self.st = gd.AlphaComplex(points=points).create_simplex_tree()\n",
    "        self._simplices = [tuple(s) for s, _ in self.st.get_simplices()]\n",
    "        max_dim = max(len(s) for s in self._simplices)\n",
    "        self._vert_idx = np.full((len(self._simplices), max_dim), -1, dtype=np.int32)\n",
    "        for i, s in enumerate(self._simplices):\n",
    "            self._vert_idx[i, :len(s)] = s\n",
    "    def compute_pd(self, func_values):\n",
    "        f_ext = np.append(func_values, -np.inf)\n",
    "        filt_vals = np.max(f_ext[self._vert_idx], axis=1)\n",
    "        for i, s in enumerate(self._simplices):\n",
    "            self.st.assign_filtration(s, float(filt_vals[i]))\n",
    "        self.st.make_filtration_non_decreasing()\n",
    "        self.st.persistence()\n",
    "        pds = []\n",
    "        for dim in range(2):\n",
    "            pd = self.st.persistence_intervals_in_dimension(dim)\n",
    "            if pd is not None and len(pd) > 0:\n",
    "                pd = pd[np.isfinite(pd[:, 1])]\n",
    "            if pd is None or len(pd) == 0:\n",
    "                pd = np.empty((0, 2))\n",
    "            pds.append(pd)\n",
    "        return tuple(pds)\n",
    "\n",
    "def phi_star_ab(phi1, phi2, a, b):\n",
    "    return np.minimum(a, 1-a) * np.maximum((phi1-b)/a, (phi2+b)/(1-a))\n",
    "\n",
    "def safe_bottleneck(pd1, pd2, e=0.01):\n",
    "    if len(pd1) == 0 and len(pd2) == 0: return 0.0\n",
    "    if len(pd1) == 0: return float(np.max((pd2[:,1]-pd2[:,0])/2))\n",
    "    if len(pd2) == 0: return float(np.max((pd1[:,1]-pd1[:,0])/2))\n",
    "    return gd.bottleneck_distance(pd1, pd2, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PDs: 100%|██████████| 500/500 [08:14<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filtrations\n",
    "Phi1, Phi2 = [], []\n",
    "for data in Data:\n",
    "    Phi1.append(compute_codensity(data, k_neighbors))\n",
    "    Phi2.append(compute_eccentricity(data))\n",
    "for phi_list in [Phi1, Phi2]:\n",
    "    for i in range(len(phi_list)):\n",
    "        f = phi_list[i]\n",
    "        fmin, fmax = f.min(), f.max()\n",
    "        if fmax > fmin:\n",
    "            phi_list[i] = (f - fmin) / (fmax - fmin)\n",
    "\n",
    "def make_cmd_filts(p1, p2): return [(1-t)*p1 + t*p2 for t in t_values]\n",
    "def make_mdf_filts(p1, p2): return [phi_star_ab(p1, p2, a, b) for a in a_fine for b in b_fine]\n",
    "def make_mdc_filts(p1, p2): return [phi_star_ab(p1, p2, a, b) for a in a_coarse for b in b_coarse]\n",
    "\n",
    "params = [('cmd', make_cmd_filts, n_cmd),\n",
    "          ('mdf', make_mdf_filts, n_md_fine),\n",
    "          ('mdc', make_mdc_filts, n_md_coarse)]\n",
    "\n",
    "PDs = {name: [None]*N for name, _, _ in params}\n",
    "for i in tqdm(range(N), desc='PDs'):\n",
    "    cst = CachedSimplexTree(Data[i])\n",
    "    phi1, phi2 = Phi1[i], Phi2[i]\n",
    "    for name, make_filts, _ in params:\n",
    "        PDs[name][i] = [cst.compute_pd(f) for f in make_filts(phi1, phi2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: cmd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: mdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances: mdc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    }
   ],
   "source": [
    "Ds = {}\n",
    "for name, _, nparam in params:\n",
    "    print(f'Distances: {name}')\n",
    "    D_H0 = np.zeros((N, N))\n",
    "    D_H1 = np.zeros((N, N))\n",
    "    for i in tqdm(range(N), leave=False):\n",
    "        for j in range(i+1, N):\n",
    "            max_d0 = max_d1 = 0.0\n",
    "            for p in range(nparam):\n",
    "                d0 = safe_bottleneck(PDs[name][i][p][0], PDs[name][j][p][0], BOTTLENECK_E)\n",
    "                d1 = safe_bottleneck(PDs[name][i][p][1], PDs[name][j][p][1], BOTTLENECK_E)\n",
    "                if d0 > max_d0: max_d0 = d0\n",
    "                if d1 > max_d1: max_d1 = d1\n",
    "            D_H0[i,j] = D_H0[j,i] = max_d0\n",
    "            D_H1[i,j] = D_H1[j,i] = max_d1\n",
    "    Ds[name] = {'H0': D_H0, 'H1': D_H1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Synthetic_distances.npy', {\n",
    "    'd_cmd_H0': Ds['cmd']['H0'], 'd_cmd_H1': Ds['cmd']['H1'],\n",
    "    'd_mdf_H0': Ds['mdf']['H0'], 'd_mdf_H1': Ds['mdf']['H1'],\n",
    "    'd_mdc_H0': Ds['mdc']['H0'], 'd_mdc_H1': Ds['mdc']['H1'],\n",
    "    'labels': Labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H0:\n",
      "  Spearman CMD vs MD121: 0.9973\n",
      "  Spearman MD10 vs MD121: 0.9920\n",
      "  Spearman CMD vs MD10: 0.9917\n",
      "\n",
      "H1:\n",
      "  Spearman CMD vs MD121: 0.9705\n",
      "  Spearman MD10 vs MD121: 0.9721\n",
      "  Spearman CMD vs MD10: 0.9876\n"
     ]
    }
   ],
   "source": [
    "triu = np.triu_indices(N, k=1)\n",
    "for hdim in ['H0', 'H1']:\n",
    "    d_cmd = Ds['cmd'][hdim][triu]\n",
    "    d_mdf = Ds['mdf'][hdim][triu]\n",
    "    d_mdc = Ds['mdc'][hdim][triu]\n",
    "    sp_cmd_mdf, _ = spearmanr(d_mdf, d_cmd)\n",
    "    sp_mdc_mdf, _ = spearmanr(d_mdf, d_mdc)\n",
    "    sp_cmd_mdc, _ = spearmanr(d_cmd, d_mdc)\n",
    "    print(f'\\n{hdim}:')\n",
    "    print(f'  Spearman CMD vs MD121: {sp_cmd_mdf:.4f}')\n",
    "    print(f'  Spearman MD10 vs MD121: {sp_mdc_mdf:.4f}')\n",
    "    print(f'  Spearman CMD vs MD10: {sp_cmd_mdc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
