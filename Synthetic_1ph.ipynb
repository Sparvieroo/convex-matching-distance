{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 1-PH: Synthetic Shapes\n",
    "\n",
    "Three 1-parameter persistence baselines:\n",
    "- **Alpha 1-PH**: standard Alpha complex persistence\n",
    "- **Codensity lower-star**: lower-star filtration from codensity (distance to k-th neighbor)\n",
    "- **Eccentricity lower-star**: lower-star filtration from eccentricity\n",
    "\n",
    "Same data generation, same classification pipeline as `Synthetic_noise.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gudhi as gd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances as pdist_sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import time, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parameters (same as Synthetic_noise.ipynb) ---\n",
    "n = 1000\n",
    "n_ex = 40\n",
    "k_neighbors = 15\n",
    "BOTTLENECK_E = 0.01\n",
    "K_KNN = 3\n",
    "NOISE_LEVELS = [0.0, 0.03, 0.06, 0.09, 0.12]\n",
    "\n",
    "class_names = ['Circle', 'Sphere', 'Torus', '3 Clusters', '2 Circles']\n",
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generators (identical to Synthetic_noise.ipynb) ---\n",
    "\n",
    "def generate_circle(n, noise=0.0):\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n)\n",
    "    pts = np.column_stack([0.5 + 0.4 * np.cos(theta),\n",
    "                           0.5 * np.ones(n),\n",
    "                           0.5 + 0.4 * np.sin(theta)])\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "\n",
    "def generate_sphere(n, noise=0.0):\n",
    "    phi = np.random.uniform(0, 2 * np.pi, n)\n",
    "    cos_theta = np.random.uniform(-1, 1, n)\n",
    "    sin_theta = np.sqrt(1 - cos_theta**2)\n",
    "    pts = np.column_stack([0.5 + 0.4 * sin_theta * np.cos(phi),\n",
    "                           0.5 + 0.4 * sin_theta * np.sin(phi),\n",
    "                           0.5 + 0.4 * cos_theta])\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "\n",
    "def generate_torus(n, noise=0.0):\n",
    "    R, r = 0.3, 0.1\n",
    "    theta = np.random.uniform(0, 2 * np.pi, n)\n",
    "    phi = np.random.uniform(0, 2 * np.pi, n)\n",
    "    pts = np.column_stack([0.5 + (R + r*np.cos(phi)) * np.cos(theta),\n",
    "                           0.5 + (R + r*np.cos(phi)) * np.sin(theta),\n",
    "                           0.5 + r * np.sin(phi)])\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "\n",
    "def generate_three_clusters(n, noise=0.0):\n",
    "    centers = np.array([[0.25, 0.25, 0.5], [0.75, 0.25, 0.5], [0.5, 0.75, 0.5]])\n",
    "    n_per = n // 3\n",
    "    parts = [c + np.random.normal(0, 0.06, (n_per if i < 2 else n - 2*n_per, 3))\n",
    "             for i, c in enumerate(centers)]\n",
    "    pts = np.vstack(parts)\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "\n",
    "def generate_two_circles(n, noise=0.0):\n",
    "    n1 = n // 2; n2 = n - n1\n",
    "    t1 = np.random.uniform(0, 2 * np.pi, n1)\n",
    "    t2 = np.random.uniform(0, 2 * np.pi, n2)\n",
    "    pts1 = np.column_stack([0.5 + 0.2*np.cos(t1), 0.5 + 0.2*np.sin(t1), 0.5*np.ones(n1)])\n",
    "    pts2 = np.column_stack([0.5 + 0.4*np.cos(t2), 0.5 + 0.4*np.sin(t2), 0.5*np.ones(n2)])\n",
    "    pts = np.vstack([pts1, pts2])\n",
    "    if noise > 0: pts += np.random.normal(0, noise, pts.shape)\n",
    "    return pts\n",
    "\n",
    "generators = [generate_circle, generate_sphere, generate_torus,\n",
    "              generate_three_clusters, generate_two_circles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core functions ---\n",
    "\n",
    "def compute_codensity(points, k):\n",
    "    nn = NearestNeighbors(n_neighbors=k+1).fit(points)\n",
    "    dists, _ = nn.kneighbors(points)\n",
    "    return dists[:, -1]\n",
    "\n",
    "def compute_eccentricity(points):\n",
    "    return np.max(pdist_sklearn(points), axis=1)\n",
    "\n",
    "def normalize_01(f):\n",
    "    fmin, fmax = f.min(), f.max()\n",
    "    if fmax > fmin:\n",
    "        return (f - fmin) / (fmax - fmin)\n",
    "    return f\n",
    "\n",
    "def safe_bottleneck(pd1, pd2, e=0.0):\n",
    "    if len(pd1) == 0 and len(pd2) == 0: return 0.0\n",
    "    if len(pd1) == 0: return float(np.max((pd2[:,1]-pd2[:,0])/2))\n",
    "    if len(pd2) == 0: return float(np.max((pd1[:,1]-pd1[:,0])/2))\n",
    "    return gd.bottleneck_distance(pd1, pd2, e)\n",
    "\n",
    "def extract_finite_pd(st, dim):\n",
    "    pd = st.persistence_intervals_in_dimension(dim)\n",
    "    if pd is not None and len(pd) > 0:\n",
    "        pd = pd[np.isfinite(pd[:, 1])]\n",
    "    if pd is None or len(pd) == 0:\n",
    "        pd = np.empty((0, 2))\n",
    "    return pd\n",
    "\n",
    "def lower_star_pd(points, func_values):\n",
    "    \"\"\"Alpha complex with lower-star filtration from vertex function.\"\"\"\n",
    "    ac = gd.AlphaComplex(points=points)\n",
    "    st = ac.create_simplex_tree()\n",
    "    for simplex, _ in st.get_simplices():\n",
    "        val = max(func_values[v] for v in simplex)\n",
    "        st.assign_filtration(simplex, float(val))\n",
    "    st.make_filtration_non_decreasing()\n",
    "    st.persistence()\n",
    "    return (extract_finite_pd(st, 0), extract_finite_pd(st, 1))\n",
    "\n",
    "def alpha_pd(points):\n",
    "    \"\"\"Standard Alpha complex persistence.\"\"\"\n",
    "    ac = gd.AlphaComplex(points=points)\n",
    "    st = ac.create_simplex_tree()\n",
    "    st.persistence()\n",
    "    return (extract_finite_pd(st, 0), extract_finite_pd(st, 1))\n",
    "\n",
    "\n",
    "def classify_knn_most_confident(D_train_list, D_test_list,\n",
    "                                labels_train, labels_test, k=3):\n",
    "    labels_train = np.asarray(labels_train)\n",
    "    labels_test = np.asarray(labels_test)\n",
    "    n_degrees = len(D_train_list)\n",
    "    n_test = D_test_list[0].shape[0]\n",
    "    final = np.zeros(n_test, dtype=int)\n",
    "    for i in range(n_test):\n",
    "        best_conf, best_pred, best_dist = -1.0, 0, np.inf\n",
    "        for d in range(n_degrees):\n",
    "            dists_i = D_test_list[d][i]\n",
    "            k_nearest = np.argsort(dists_i)[:k]\n",
    "            nn_labels = labels_train[k_nearest]\n",
    "            pred = Counter(nn_labels).most_common(1)[0][0]\n",
    "            conf = np.sum(nn_labels == pred) / k\n",
    "            avg_d = np.mean(dists_i[k_nearest])\n",
    "            if conf > best_conf or (conf == best_conf and avg_d < best_dist):\n",
    "                best_conf, best_pred, best_dist = conf, pred, avg_d\n",
    "        final[i] = best_pred\n",
    "    return float(np.mean(final == labels_test))\n",
    "\n",
    "\n",
    "def extract_distance_blocks(D_full, train_idx, test_idx):\n",
    "    return D_full[np.ix_(train_idx, train_idx)], D_full[np.ix_(test_idx, train_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NOISE = 0.0\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PDs: 100%|██████████| 200/200 [01:08<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Alpha 1-PH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Codensity lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Ecc lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Alpha 1-PH: 61.17% ± 14.16%\n",
      "       Codensity lower-star: 93.17% ± 3.37%\n",
      "             Ecc lower-star: 71.33% ± 7.85%\n",
      "\n",
      "============================================================\n",
      "NOISE = 0.03\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PDs: 100%|██████████| 200/200 [00:45<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Alpha 1-PH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Codensity lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Ecc lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Alpha 1-PH: 48.00% ± 8.69%\n",
      "       Codensity lower-star: 95.67% ± 2.38%\n",
      "             Ecc lower-star: 23.50% ± 4.18%\n",
      "\n",
      "============================================================\n",
      "NOISE = 0.06\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PDs: 100%|██████████| 200/200 [00:47<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Alpha 1-PH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Codensity lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Ecc lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Alpha 1-PH: 34.00% ± 9.20%\n",
      "       Codensity lower-star: 81.67% ± 3.94%\n",
      "             Ecc lower-star: 22.00% ± 2.87%\n",
      "\n",
      "============================================================\n",
      "NOISE = 0.09\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PDs: 100%|██████████| 200/200 [00:47<00:00,  4.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Alpha 1-PH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Codensity lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Ecc lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Alpha 1-PH: 38.17% ± 4.04%\n",
      "       Codensity lower-star: 78.00% ± 4.64%\n",
      "             Ecc lower-star: 24.83% ± 6.85%\n",
      "\n",
      "============================================================\n",
      "NOISE = 0.12\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PDs: 100%|██████████| 200/200 [00:46<00:00,  4.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Alpha 1-PH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Codensity lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Distances: Ecc lower-star\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Alpha 1-PH: 31.50% ± 3.83%\n",
      "       Codensity lower-star: 69.33% ± 3.51%\n",
      "             Ecc lower-star: 22.17% ± 6.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "methods = ['Alpha 1-PH', 'Codensity lower-star', 'Ecc lower-star']\n",
    "all_results = {}\n",
    "\n",
    "for noise in NOISE_LEVELS:\n",
    "    print(f'\\n{\"=\"*60}')\n",
    "    print(f'NOISE = {noise}')\n",
    "    print(f'{\"=\"*60}')\n",
    "\n",
    "    # Generate data\n",
    "    #np.random.seed(42)\n",
    "    Data, Labels = [], []\n",
    "    for cls_idx, gen in enumerate(generators):\n",
    "        for _ in range(n_ex):\n",
    "            Labels.append(cls_idx)\n",
    "            Data.append(gen(n, noise=noise))\n",
    "    Labels = np.array(Labels)\n",
    "    N = len(Data)\n",
    "\n",
    "    # Compute PDs for each method\n",
    "    PDs = {m: [] for m in methods}\n",
    "\n",
    "    for i in tqdm(range(N), desc='Computing PDs'):\n",
    "        # Alpha 1-PH\n",
    "        PDs['Alpha 1-PH'].append(alpha_pd(Data[i]))\n",
    "\n",
    "        # Codensity lower-star\n",
    "        cod = normalize_01(compute_codensity(Data[i], k_neighbors))\n",
    "        PDs['Codensity lower-star'].append(lower_star_pd(Data[i], cod))\n",
    "\n",
    "        # Eccentricity lower-star\n",
    "        ecc = normalize_01(compute_eccentricity(Data[i]))\n",
    "        PDs['Ecc lower-star'].append(lower_star_pd(Data[i], ecc))\n",
    "\n",
    "    # Distance matrices\n",
    "    Ds = {}\n",
    "    for mname in methods:\n",
    "        print(f'  Distances: {mname}')\n",
    "        D_H0 = np.zeros((N, N))\n",
    "        D_H1 = np.zeros((N, N))\n",
    "        for i in tqdm(range(N), leave=False):\n",
    "            for j in range(i+1, N):\n",
    "                d0 = safe_bottleneck(PDs[mname][i][0], PDs[mname][j][0], BOTTLENECK_E)\n",
    "                d1 = safe_bottleneck(PDs[mname][i][1], PDs[mname][j][1], BOTTLENECK_E)\n",
    "                D_H0[i,j] = D_H0[j,i] = d0\n",
    "                D_H1[i,j] = D_H1[j,i] = d1\n",
    "        Ds[mname] = (D_H0, D_H1)\n",
    "\n",
    "    # 10-fold CV\n",
    "    accs = {m: [] for m in methods}\n",
    "    for fold in range(10):\n",
    "        idx_tr, idx_te, lab_tr, lab_te = train_test_split(\n",
    "            np.arange(N), Labels, train_size=0.7, stratify=Labels, random_state=42+fold)\n",
    "        for mname in methods:\n",
    "            D0, D1 = Ds[mname]\n",
    "            blocks = [extract_distance_blocks(D, idx_tr, idx_te) for D in [D0, D1]]\n",
    "            accs[mname].append(classify_knn_most_confident(\n",
    "                [b[0] for b in blocks], [b[1] for b in blocks],\n",
    "                lab_tr, lab_te, K_KNN))\n",
    "\n",
    "    all_results[noise] = accs\n",
    "    for m in methods:\n",
    "        print(f'  {m:>25}: {np.mean(accs[m]):.2%} ± {np.std(accs[m]):.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Noise     Alpha 1-PH               Codensity lower-star     Ecc lower-star           \n",
      "================================================================================\n",
      "0.00      61.17% ± 14.16%          93.17% ± 3.37%           71.33% ± 7.85%           \n",
      "0.03      48.00% ± 8.69%           95.67% ± 2.38%           23.50% ± 4.18%           \n",
      "0.06      34.00% ± 9.20%           81.67% ± 3.94%           22.00% ± 2.87%           \n",
      "0.09      38.17% ± 4.04%           78.00% ± 4.64%           24.83% ± 6.85%           \n",
      "0.12      31.50% ± 3.83%           69.33% ± 3.51%           22.17% ± 6.41%           \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def fmt(v): return f'{np.mean(v):.2%} ± {np.std(v):.2%}'\n",
    "\n",
    "print('=' * 80)\n",
    "print(f'{\"Noise\":<10}', end='')\n",
    "for m in methods:\n",
    "    print(f'{m:<25}', end='')\n",
    "print()\n",
    "print('=' * 80)\n",
    "for noise in NOISE_LEVELS:\n",
    "    r = all_results[noise]\n",
    "    print(f'{noise:<10.2f}', end='')\n",
    "    for m in methods:\n",
    "        print(f'{fmt(r[m]):<25}', end='')\n",
    "    print()\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'Synthetic_1ph_{n:03d}.npy', all_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
